{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba4f40d1",
   "metadata": {},
   "source": [
    "## Import program dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f8ffc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd20987",
   "metadata": {},
   "source": [
    "## Load the serialized black and white colorizer model and cluster center points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e131b2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prototxt = '[YOUR WORKSPACE]\\\\colorization_deploy_v2.prototxt'\n",
    "model = '[YOUR WORKSPACE]\\\\colorization_release_v2.caffemodel'\n",
    "points = '[YOUR WORKSPACE]\\\\pts_in_hull.npy]'\n",
    "net = cv.dnn.readNetFromCaffe(prototxt, model)\n",
    "pts = np.load(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2089dec",
   "metadata": {},
   "source": [
    "## Add the cluster centers as 1x1 convolutions to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bc6f266",
   "metadata": {},
   "outputs": [],
   "source": [
    "class8 = net.getLayerId('class8_ab')\n",
    "conv8 = net.getLayerId('conv8_313_rh')\n",
    "pts = pts.transpose().reshape(2, 313, 1, 1)\n",
    "net.getLayer(class8).blobs = [pts.astype('float32')]\n",
    "net.getLayer(conv8).blobs = [np.full([1, 313], 2.606, dtype = 'float32')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866569e0",
   "metadata": {},
   "source": [
    "## Load (and display) the input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db586cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '[YOUR WORKSPACE]\\\\[YOUR IMAGE.JPG]'\n",
    "image = cv.imread(filename)\n",
    "cv.imshow('Original', image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ad00c7",
   "metadata": {},
   "source": [
    "## Scale the pixel intensities to the range [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "235b47ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled = image.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a85c20",
   "metadata": {},
   "source": [
    "## Convert the image from BGR to Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9f7ae5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab = cv.cvtColor(scaled, cv.COLOR_BGR2LAB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4b02bf",
   "metadata": {},
   "source": [
    "## Resize the image to 224 x 224 (required size for the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40e79661",
   "metadata": {},
   "outputs": [],
   "source": [
    "resized = cv.resize(lab, (224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef485db1",
   "metadata": {},
   "source": [
    "## Extract the L channel, then perform mean centering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bb4a35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lchannel = cv.split(resized)[0]\n",
    "Lchannel -= 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183ced2d",
   "metadata": {},
   "source": [
    "## Pass the L channel through the network, which then returns the ab values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd7cc5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.setInput(cv.dnn.blobFromImage(Lchannel))\n",
    "ab = net.forward()[0, :, :, :].transpose((1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1db3bc0",
   "metadata": {},
   "source": [
    "## Resize the ab channel to the size of the original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ffd8399",
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = cv.resize(ab, (image.shape[1], image.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b7ee85",
   "metadata": {},
   "source": [
    "## Grab the L channel (from the original image, not the resized one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5f34850",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = cv.split(lab)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fb2b01",
   "metadata": {},
   "source": [
    "## Concatenate the L channel to the ab channel (this creates the colorized image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30103bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "colorized = np.concatenate((L[:, :, np.newaxis], ab), axis = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6165fa8d",
   "metadata": {},
   "source": [
    "## Convert the colorized image from Lab back to BGR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab2d1e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "colorized = cv.cvtColor(colorized, cv.COLOR_LAB2BGR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dbb84e",
   "metadata": {},
   "source": [
    "## Clip any values that fall outside the range [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98da9e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "colorized = np.clip(colorized, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a6f700",
   "metadata": {},
   "source": [
    "## Scale the pixel intensities back to the range [0, 255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27763717",
   "metadata": {},
   "outputs": [],
   "source": [
    "colorized = (255 * colorized).astype('uint8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17af365",
   "metadata": {},
   "source": [
    "## Display the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "033834e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.imshow('Result', colorized)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e8de08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
